---
title: "MA376 Lesson 1: Public Sentiment on the Use of Facial Recognition"
author: ""
output: pdf_document
---
  
  ```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Background:** In the past, facial recognition technology (FRT) was viewed as something straight out of science fiction. However, over the past decade, this technology has become viable and increasingly widespread. Recently, several lawmakers have expressed concern that certain groups are not using FRT responsibly. Let us examine public sentiment on this topic using  a dataset based on a portion of the Pew Research Center's American Trends Panel (Pew Research Center, 2019).^[All variable modifications are documented [here](https://github.com/tooderful/MA376/tree/master/LSN%201/Prep%20Files). Additional information about the Pew study can be found in the ATP W49 methodology pdf.] The variables in the dataset are described in the table.


\begin{table}[h!]
\begin{tabular}{|l|l|}
\hline
\textbf{Variable} & \textbf{Description} \\ \hline
TrustAdvertisers & Do you trust advertisers to use facial recognition technology responsibly? \\ \hline
TrustTechCompany & Do you trust technology companies to use facial recognition technology responsibly? \\ \hline
TrustPolice & Do you trust law enforcement to use facial recognition technology responsibly? \\ \hline
Education & College Educated \\ \hline
Race & Race \\ \hline
\end{tabular}
\end{table}

### Step 1: Ask a research question
Write a research question involving two variables in the dataset.

*Type your answers here*
\vspace{.5in}

### Step 2:  Design a study and collect data
Use no more than three sentences to describe the data. Be sure to indicate how many subjects are in the analysis and what values the variables take on. 
*Type your answers here*
\vspace{.5in}

### Step 3: Explore the data
\begin{enumerate}
\item[a.] Create a bar graph of the response variable. Describe the plot.

\textit{Type your answers here}
\vspace{.5in}

\item[b.] Create a contingency table and mosaic plot to summarize the response and explanatory variables. Does the plot suggest an association exists? Explain. 

\textit{Type your answers here}
\vspace{.5in}

\item[c.] Identify a potential confounding variable and explain how it may be confounding in this study. 

\textit{Type your answers here}
\vspace{.5in}

\item[d.] Create another mosaic plot that includes the third variable. Does the plot suggest that the third variable is confounding? Explain.

\textit{Type your answers here}
\vspace{.5in}

\item[e.] Construct the Sources of Variation Diagram:
\end{enumerate}
\textit{Type your answers here}^[A convenient table generator can be found  [here](https://www.tablesgenerator.com/latex_tables).]




\vspace{.5in}
### Step 4: Draw inferences beyond the data
Name one theory-based approach we could use to determine if there was a statistically significant difference between the levels of the explanatory variable.

*Type your answers here*
\vspace{.5in}

### Step 5: Formulate conclusions
How far can we generalize our conclusions? Could we draw a cause-effect conclusion if we observed statistically significant differences in Step 4? Why or why not?

*Type your answers here*
\vspace{.5in}

### Step 6: Look back and ahead
What are two limitations to our approach? Discuss how we could address these limitations in a future study.

*Type your answers here*
\vspace{.5in}

### Further Investigation
With your group partner, explore another response variable. Are the conclusions the same?
*Type your answers here*

\newpage
### References
Pew Research Center. American Trends Panel Wave 49. https://www.pewresearch.org/internet/dataset/american-trends-panel-wave-49/ (2019). Accessed: 2020-08-12.
 
\newpage
```{r, message=FALSE, warning=FALSE}
library('tidyverse')

dat <- read_csv('C:/Users/annyclaude.joseph/Documents/Joseph_Teaching/AY21-1/MA376/Lectures/American Trends Panel/W49_Jun19/Wave49.csv')
# head(dat)


# Insert your code here
``` 


